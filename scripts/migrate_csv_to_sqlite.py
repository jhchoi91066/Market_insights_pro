# -*- coding: utf-8 -*-
"""
CSV ë°ì´í„°ë¥¼ SQLiteë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ ì¿ íŒ¡ CSV ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ SQLite ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì´ì „í•©ë‹ˆë‹¤.
"""
import os
import sys
import pandas as pd
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from core.models import db_manager, Product, ScrapingSession


def migrate_csv_to_sqlite(csv_file_path: str):
    """
    CSV íŒŒì¼ì˜ ë°ì´í„°ë¥¼ SQLite ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤.
    
    Args:
        csv_file_path: ë§ˆì´ê·¸ë ˆì´ì…˜í•  CSV íŒŒì¼ ê²½ë¡œ
    """
    print(f"=== CSV â†’ SQLite ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘ ===")
    print(f"CSV íŒŒì¼: {csv_file_path}")
    
    # CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(csv_file_path):
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file_path}")
        return False
    
    # CSV ë°ì´í„° ë¡œë“œ
    try:
        df = pd.read_csv(csv_file_path)
        print(f"ğŸ“Š CSV ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        print(f"ì»¬ëŸ¼: {list(df.columns)}")
    except Exception as e:
        print(f"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±
    db_manager.create_tables()
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
    session = db_manager.get_session()
    
    try:
        # ê¸°ì¡´ ë°ì´í„° í™•ì¸ (ì¤‘ë³µ ë°©ì§€)
        existing_products = session.query(Product).count()
        print(f"ğŸ“ˆ ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ìƒí’ˆ ìˆ˜: {existing_products}")
        
        # CSV ë°ì´í„°ë¥¼ Product ëª¨ë¸ë¡œ ë³€í™˜í•˜ì—¬ ì‚½ì…
        products_added = 0
        products_skipped = 0
        
        for index, row in df.iterrows():
            # ì¤‘ë³µ ì²´í¬ (product_id ê¸°ì¤€)
            existing = session.query(Product).filter_by(product_id=row['product_id']).first()
            if existing:
                products_skipped += 1
                continue
            
            # Product ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            product = Product(
                product_id=row['product_id'],
                product_title=row['product_title'],
                product_category=row['product_category'],
                discounted_price=int(row['discounted_price']) if pd.notna(row['discounted_price']) else 0,
                product_rating=float(row['product_rating']) if pd.notna(row['product_rating']) else 0.0,
                total_reviews=int(row['total_reviews']) if pd.notna(row['total_reviews']) else 0,
                purchased_last_month=int(row['purchased_last_month']) if pd.notna(row['purchased_last_month']) else 0,
                brand=row['brand'] if pd.notna(row['brand']) and row['brand'] != 'N/A' else None,
                seller=row['seller'] if pd.notna(row['seller']) and row['seller'] != 'N/A' else None,
                is_rocket=row['is_rocket'] == 'Y' if pd.notna(row['is_rocket']) else False,
                product_url=None,  # CSVì—ëŠ” URLì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŒ
                scraped_at=datetime.strptime(row['scraped_at'], "%Y-%m-%d %H:%M:%S") if pd.notna(row['scraped_at']) else datetime.utcnow()
            )
            
            session.add(product)
            products_added += 1
        
        # ìŠ¤í¬ë ˆì´í•‘ ì„¸ì…˜ ì •ë³´ ì¶”ê°€ (ë©”íƒ€ë°ì´í„°)
        filename = os.path.basename(csv_file_path)
        keyword = filename.replace('_products.csv', '').replace('_', ' ')
        
        scraping_session = ScrapingSession(
            keyword=keyword,
            products_found=len(df),
            products_saved=products_added,
            session_status='completed' if products_added > 0 else 'partial',
            started_at=datetime.utcnow(),
            completed_at=datetime.utcnow()
        )
        session.add(scraping_session)
        
        # ì»¤ë°‹
        session.commit()
        
        print(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        print(f"   - ìƒˆë¡œ ì¶”ê°€ëœ ìƒí’ˆ: {products_added}ê°œ")
        print(f"   - ì¤‘ë³µìœ¼ë¡œ ìŠ¤í‚µëœ ìƒí’ˆ: {products_skipped}ê°œ")
        print(f"   - ìŠ¤í¬ë ˆì´í•‘ ì„¸ì…˜ ì¶”ê°€: 1ê°œ")
        
        return True
        
    except Exception as e:
        session.rollback()
        print(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        return False
        
    finally:
        db_manager.close_session(session)


def verify_migration():
    """
    ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    print(f"\n=== ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ===")
    
    session = db_manager.get_session()
    try:
        # ìƒí’ˆ ìˆ˜ í™•ì¸
        products_count = session.query(Product).count()
        print(f"ğŸ“Š ì´ ìƒí’ˆ ìˆ˜: {products_count}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ ìˆ˜
        from sqlalchemy import func
        categories = session.query(Product.product_category, func.count(Product.id)).group_by(Product.product_category).all()
        
        print("ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ ìˆ˜:")
        for category, count in categories:
            print(f"   - {category}: {count}ê°œ")
        
        # ìŠ¤í¬ë ˆì´í•‘ ì„¸ì…˜ ìˆ˜
        sessions_count = session.query(ScrapingSession).count()
        print(f"ğŸ“Š ìŠ¤í¬ë ˆì´í•‘ ì„¸ì…˜ ìˆ˜: {sessions_count}")
        
        # ìµœê·¼ ìƒí’ˆ 5ê°œ ì¶œë ¥
        recent_products = session.query(Product).order_by(Product.scraped_at.desc()).limit(5).all()
        print(f"\nğŸ” ìµœê·¼ ìƒí’ˆ 5ê°œ:")
        for product in recent_products:
            print(f"   - {product.product_id}: {product.product_title[:50]}...")
            
    except Exception as e:
        print(f"âŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        db_manager.close_session(session)


if __name__ == '__main__':
    # CSV íŒŒì¼ ê²½ë¡œ
    csv_file = "/Users/jinhochoi/Desktop/ê°œë°œ/Market_insights/data/ë¸”ë£¨íˆ¬ìŠ¤_ì´ì–´í°_products.csv"
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    success = migrate_csv_to_sqlite(csv_file)
    
    if success:
        # ê²€ì¦
        verify_migration()
    
    print("\n=== ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ ===")