# -*- coding: utf-8 -*-
"""
Amazon Market Insights Pro - FastAPI Main Application
Provides web UI and API endpoints for Amazon market analysis.
"""
import json
from typing import List
from fastapi import FastAPI, Request, Form, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import asyncio
import traceback
from datetime import datetime

# --- ë¡œê¹… í—¬í¼ í•¨ìˆ˜ ---
def log_to_file(message: str):
    """ë””ë²„ê¹… ë©”ì‹œì§€ë¥¼ íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤."""
    with open("debug_log.txt", "a", encoding="utf-8") as f:
        f.write(f"{datetime.now().isoformat()} - {message}\n")
    print(message) # ì½˜ì†”ì—ë„ ì¶œë ¥

# ë¶„ì„ê¸° ëª¨ë“ˆì€ ì‹œì‘ ì‹œ ë¡œë“œí•´ë„ ì•ˆì „í•©ë‹ˆë‹¤.
from core.analyzer_v2 import SQLiteMarketAnalyzer

app = FastAPI(
    title="Amazon Market Insights Pro",
    description="Amazon product market analysis and competition research tool",
    version="1.1.0", # WebSocket support added
)

# --- v2 MVP ì„¤ì • ---
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# ë¶„ì„ê¸° ë° ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
sqlite_analyzer = SQLiteMarketAnalyzer()

# Redis ìºì‹œ ë§¤ë‹ˆì € import ë° ì´ˆê¸°í™”
from core.cache import get_cache_manager
cache_manager = get_cache_manager()

# --- WebSocket ì—°ê²° ê´€ë¦¬ ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        log_to_file(f"WebSocket ì—°ê²°: {len(self.active_connections)}ëª… ì ‘ì† ì¤‘")

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
        log_to_file(f"WebSocket ì—°ê²° í•´ì œ: {len(self.active_connections)}ëª… ì ‘ì† ì¤‘")

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

ws_manager = ConnectionManager()

# --- ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ ê¸€ë¡œë²Œ ë½ ---
scraping_lock = asyncio.Lock()  # í•œ ë²ˆì— í•˜ë‚˜ì˜ ìŠ¤í¬ë˜í•‘ë§Œ í—ˆìš©

# -----------------------------------------------------------------------------
# WebSocket ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------------------------------------
@app.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    await ws_manager.connect(websocket)
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ë¥¼ ë°›ì„ ìˆ˜ ìˆì§€ë§Œ, í˜„ì¬ëŠ” ì—°ê²° ìœ ì§€ ëª©ì 
            await websocket.receive_text()
    except WebSocketDisconnect:
        ws_manager.disconnect(websocket)

# -----------------------------------------------------------------------------
# MVP ì›¹ í˜ì´ì§€ ë¼ìš°íŒ…
# -----------------------------------------------------------------------------
@app.get("/", response_class=HTMLResponse)
def read_root(request: Request):
    return templates.TemplateResponse("index.html", {"request": request, "title": "Amazon Market Insights Pro"})

@app.post("/report", response_class=HTMLResponse)
def create_report(request: Request, keyword: str = Form(...)):
    log_to_file(f"--- ë³´ê³ ì„œ ìƒì„± ì‹œì‘: '{keyword}' ---")
    scraper = None # finallyì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë¯¸ë¦¬ ì„ ì–¸
    
    async def broadcast_status(status: str, progress: int, message: str):
        """Helper to broadcast status updates."""
        log_to_file(f"[{progress}%] {message}")
        update = json.dumps({
            "status": status,
            "progress": progress,
            "message": message
        })
        await ws_manager.broadcast(update)

    try:
        # 1. ìºì‹œëœ ê²°ê³¼ í™•ì¸ (ê°€ì¥ ë¨¼ì € ì²´í¬)
        await broadcast_status('caching', 0, f"Checking cache for '{keyword}'...")
        cached_result = cache_manager.get_analysis_result(keyword)
        if cached_result:
            log_to_file(f"ğŸ¯ ìºì‹œ HIT! '{keyword}' ê²°ê³¼ë¥¼ ìºì‹œì—ì„œ ë°˜í™˜")
            await broadcast_status('completed', 100, "Cache hit! Returning cached data.")
            return templates.TemplateResponse("report.html", {
                "request": request, 
                "report": cached_result,
                "cached": True
            })
        
        await broadcast_status('initializing', 5, f"Cache miss. Starting new analysis for '{keyword}'.")
        
        # --- ì§€ì—° ë¡œë”©(Lazy Loading) ì ìš© ---
        await broadcast_status('loading', 10, "Loading scraper module...")
        from core.scraper import AmazonScraper
        scraper = AmazonScraper()

        # --- ë¸Œë¼ìš°ì € ì‹¤í–‰ ---
        await broadcast_status('browser_starting', 15, "Starting browser...")
        await scraper.start_browser()

        # 2. ê¸°ì¡´ ë°ì´í„° í™•ì¸
        await broadcast_status('data_checking', 20, "Checking for existing data in database...")
        existing_count = 0
        try:
            existing_check = sqlite_analyzer.analyze_category_competition(keyword)
            existing_count = existing_check.get('competitor_count', 0) if existing_check else 0
        except Exception as e:
            log_to_file(f"ê¸°ì¡´ ë°ì´í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        log_to_file(f"ê¸°ì¡´ ë°ì´í„° {existing_count}ê°œ í™•ì¸")

        # 3. í•„ìš”ì‹œ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ (ë™ì‹œì„± ì œì–´)
        if existing_count < 30:
            await broadcast_status('scraping', 30, "Existing data is insufficient. Starting live scraping...")
            
            if scraping_lock.locked():
                await broadcast_status('waiting', 25, "Another analysis is in progress. Queued...")
            
            async with scraping_lock:
                await broadcast_status('scraping_active', 40, f"Actively scraping Amazon for '{keyword}'...")
                db_result = await scraper.scrape_and_save_to_db(keyword, max_products=100)
            
            if not db_result or not db_result.get('success'):
                error_reason = db_result.get('message', 'Unknown scraping error') if db_result else 'Scraper did not respond'
                await broadcast_status('error', 0, f"Scraping failed: {error_reason}")
                return templates.TemplateResponse("error.html", {
                    "request": request,
                    "error_message": f"Failed to collect data for '{keyword}' category.",
                    "error_reason": error_reason
                })
        else:
            await broadcast_status('analyzing', 70, "Sufficient data found in database. Skipping scraping.")

        # 4. ë¶„ì„ ì‹¤í–‰
        await broadcast_status('analyzing', 80, "Analyzing market competition...")
        competition_report = sqlite_analyzer.analyze_category_competition(keyword)
        
        await broadcast_status('analyzing', 90, "Calculating market saturation...")
        saturation_report = sqlite_analyzer.calculate_market_saturation(keyword)
        
        report_data = {**competition_report, **saturation_report, 'keyword': keyword}

        # 5. ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (1ì‹œê°„ TTL)
        await broadcast_status('caching', 95, "Saving analysis results to cache...")
        cache_manager.set_analysis_result(keyword, report_data, ttl_hours=1)

        # 6. ì™„ë£Œ
        await broadcast_status('completed', 100, "Analysis complete! Rendering report.")

        # 7. ê²°ê³¼ í˜ì´ì§€ ë Œë”ë§
        return templates.TemplateResponse("report.html", {"request": request, "report": report_data})
    
    except Exception as e:
        error_trace = traceback.format_exc()
        log_to_file(f"!!! ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        log_to_file(error_trace)
        await broadcast_status('error', 0, f"An unexpected error occurred: {e}")
        return templates.TemplateResponse("error.html", {
            "request": request,
            "error_message": "An unexpected error occurred while generating the analysis report.",
            "error_reason": str(e)
        })
    finally:
        if scraper:
            await scraper.close_browser()
            log_to_file("ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")
        log_to_file(f"--- ë³´ê³ ì„œ ìƒì„± ì¢…ë£Œ: '{keyword}' ---")


# -----------------------------------------------------------------------------
# ìºì‹œ ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------------------------------------

@app.get("/api/cache/stats")
def get_cache_statistics():
    """ìºì‹œ í†µê³„ ì •ë³´ ì¡°íšŒ"""
    try:
        stats = cache_manager.get_cache_stats()
        health = cache_manager.health_check()
        return {"status": "success", "cache_health": health, "statistics": stats}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.get("/api/cache/health")
def cache_health_check():
    """Redis ì—°ê²° ìƒíƒœ í™•ì¸"""
    try:
        health = cache_manager.health_check()
        return {"status": "success", **health}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.delete("/api/cache/analysis")
def flush_analysis_cache():
    """ë¶„ì„ ê²°ê³¼ ìºì‹œ ì „ì²´ ì‚­ì œ"""
    try:
        deleted_count = cache_manager.flush_analysis_cache()
        return {"status": "success", "message": f"Deleted {deleted_count} entries.", "deleted_count": deleted_count}
    except Exception as e:
        return {"status": "error", "message": str(e)}

# -----------------------------------------------------------------------------
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì´ë²¤íŠ¸ 
# -----------------------------------------------------------------------------

@app.on_event("startup")
def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰"""
    log_to_file("ğŸš€ Market Insights Pro ì‹œì‘")
    try:
        health = cache_manager.health_check()
        if health['status'] == 'healthy':
            log_to_file(f"âœ… Redis ì—°ê²° ì„±ê³µ (ì‘ë‹µì‹œê°„: {health['response_time_ms']}ms)")
        else:
            log_to_file(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨: {health.get('error', 'Unknown error')}")
    except Exception as e:
        log_to_file(f"âŒ Redis ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

@app.on_event("shutdown") 
def shutdown_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    log_to_file("ğŸ”„ Market Insights Pro ì¢…ë£Œ")

# -----------------------------------------------------------------------------
# ê°œë°œìš© ì—”ë“œí¬ì¸íŠ¸ (í”„ë¡œë•ì…˜ì—ì„œëŠ” ì œê±° ê¶Œì¥)
# -----------------------------------------------------------------------------

@app.get("/debug/cache-test")
def debug_cache_test():
    """ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸"""
    try:
        test_data = {"test": True, "timestamp": datetime.now().isoformat()}
        cache_manager.set_analysis_result("debug_test", test_data, ttl_hours=1)
        retrieved = cache_manager.get_analysis_result("debug_test")
        stats = cache_manager.get_cache_stats()
        return {"status": "success", "data": retrieved, "stats": stats}
    except Exception as e:
        return {"status": "error", "message": str(e)}
